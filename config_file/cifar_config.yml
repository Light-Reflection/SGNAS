cuda: True
ngpu: 4
num_workers: 8
seed: 42

log_dir: "./logs/"
write_dir: "./logs/tb/"
path_to_save_model: ./logs/best_model.pth
path_to_save_generator: ./logs/best_generator.pth
path_to_best_avg_generator: ./logs/best_avg.pth
path_to_fianl_generator: ./logs/final.pth
model_pretrained: ./logs/best_model.pth
generator_pretrained: ./logs/best_avg.pth

path_to_save_scratch: ./logs/best_scratch.pth
path_to_save_architecture: ./logs/architecture.csv
path_to_save_evaluate_architecture: ./logs/evaluate_architecture.csv

path_to_prior_pool : ./logs/prior_pool.json

path_to_generator_eval: ./logs/generator_evaluate.csv
path_to_generator_eval_avg: ./logs/generator_evaluate_avg.csv
path_to_supernet_eval: ./logs/supernet_evaluate.csv


# Search epoch
generator: "singan"
hc_dim: 10
warmup_epochs: 1
search_epochs: 50

tau_decay: 0.95
alpha: 0.0003
loss_penalty: 1.2
noise_weight: 0.0
low_flops: 80
high_flops: 120
pool_size: 1
#####

epochs: 200
batch_size: 512
print_freq: 100

dataset: cifar100
classes: 100
dataset_dir: ./data/
input_size: 32
train_portion: 0.8 # Set 0.8 for architecture searching and 1 for architecture evaluating
mean: [0.49139968, 0.48215827, 0.44653124]
std: [0.2023, 0.1994, 0.2010]


optim_state: !include ./optim_state.yml
g_optim_state: !include ./g_optim_state.yml

lr_scheduler: cosine
step_size: 80
decay_ratio: 0.1


split_blocks: 6
kernels_nums: 4
min_expansion: 2
expansion: 6
static_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
#[max_expansion, out, kernels, stride, split_block, se]
l_cfgs: [[6, 32,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 32,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 40,  [3, 5, 7, "skip"], 2, 4, False],
         [6, 40,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 40,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 40,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 80,  [3, 5, 7, "skip"], 2, 4, False],
         [6, 80,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 80,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 80,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 96,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 96,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 96,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 96,  [3, 5, 7, "skip"], 1, 4, False],
         [6, 192, [3, 5, 7, "skip"], 2, 4, False],
         [6, 192, [3, 5, 7, "skip"], 1, 4, False],
         [6, 192, [3, 5, 7, "skip"], 1, 4, False],
         [6, 192, [3, 5, 7, "skip"], 1, 4, False],
         [6, 320, [3, 5, 7, "skip"], 1, 4, False]]
